# Modelos de Machine Learning - GuÃ­a de Estudio

Este repositorio contiene ejemplos prÃ¡cticos y didÃ¡cticos de los algoritmos fundamentales de Machine Learning, con visualizaciones que te ayudarÃ¡n a entender cÃ³mo funcionan. Cada script genera grÃ¡ficas que se guardan en la carpeta `imgs/`.

---

## ğŸ“š Tabla de Contenidos

1. [RegresiÃ³n Lineal](#1-regresiÃ³n-lineal)
2. [ClasificaciÃ³n con RegresiÃ³n LogÃ­stica](#2-clasificaciÃ³n-con-regresiÃ³n-logÃ­stica)
3. [ClasificaciÃ³n Multi-clase: Iris Dataset](#3-clasificaciÃ³n-multi-clase-iris-dataset)
4. [Clustering: Agrupamiento de Datos](#4-clustering-agrupamiento-de-datos)
5. [Competencia de Modelos de RegresiÃ³n](#5-competencia-de-modelos-de-regresiÃ³n)
6. [Competencia de Modelos de ClasificaciÃ³n](#6-competencia-de-modelos-de-clasificaciÃ³n)

---

## 1. RegresiÃ³n Lineal

**Script:** `01_regresion_lineal.py`

### Â¿QuÃ© es la RegresiÃ³n Lineal?

La regresiÃ³n lineal es uno de los algoritmos mÃ¡s simples de machine learning. Su objetivo es encontrar una lÃ­nea recta que mejor se ajuste a un conjunto de datos. Imagina que tienes puntos en una grÃ¡fica y quieres dibujar una lÃ­nea que pase lo mÃ¡s cerca posible de todos ellos.

La ecuaciÃ³n de la lÃ­nea recta es:

$$y = mx + b$$

Donde:
- $y$ es el valor que queremos predecir
- $x$ es el valor que conocemos
- $m$ es la pendiente (quÃ© tan inclinada estÃ¡ la lÃ­nea)
- $b$ es el intercepto (dÃ³nde cruza el eje Y)

### Visualizaciones Generadas

#### 1.1 Datos Sin Ruido - Scatter Plot
![Datos lineales sin ruido](imgs/01_regresion_datos_lineales_scatter.jpg)

Esta grÃ¡fica muestra los datos originales en un scatter plot (grÃ¡fica de puntos). Cuando los datos no tienen ruido, los puntos forman un patrÃ³n muy claro y predecible. Es como conectar los puntos en un dibujo: es fÃ¡cil ver por dÃ³nde deberÃ­a pasar la lÃ­nea.

#### 1.2 Datos Sin Ruido - Modelo Ajustado
![Modelo ajustado sin ruido](imgs/01_regresion_datos_lineales_modelo_ajustado.jpg)

AquÃ­ vemos la lÃ­nea roja que el algoritmo encontrÃ³. Esta lÃ­nea pasa casi perfectamente por todos los puntos porque los datos son muy limpios. El $R^2$ (R cuadrado) nos dice quÃ© tan bien la lÃ­nea explica los datos: un valor cercano a 1.0 significa que el ajuste es excelente.

#### 1.3 Datos Con Ruido - Scatter Plot
![Datos lineales con ruido](imgs/01_regresion_datos_lineales_con_ruido_scatter.jpg)

En la vida real, los datos nunca son perfectos. Esta grÃ¡fica muestra datos con "ruido": los puntos no estÃ¡n perfectamente alineados. Es como tomar mediciones en un experimento real donde siempre hay pequeÃ±os errores.

#### 1.4 Datos Con Ruido - Modelo Ajustado
![Modelo ajustado con ruido](imgs/01_regresion_datos_lineales_con_ruido_modelo_ajustado.jpg)

Incluso con ruido, el algoritmo puede encontrar una lÃ­nea que captura la tendencia general. La lÃ­nea roja no pasa exactamente por todos los puntos, pero representa el patrÃ³n promedio. Esto es normal y esperado cuando trabajamos con datos del mundo real.

### ConclusiÃ³n

La regresiÃ³n lineal es Ãºtil cuando queremos:
- Predecir un valor numÃ©rico (como precio, temperatura, etc.)
- Los datos muestran una relaciÃ³n aproximadamente lineal
- Necesitamos un modelo simple y fÃ¡cil de interpretar

---

## 2. ClasificaciÃ³n con RegresiÃ³n LogÃ­stica

**Script:** `02_clasificacion.py`

### Â¿QuÃ© es la ClasificaciÃ³n?

A diferencia de la regresiÃ³n (que predice nÃºmeros), la clasificaciÃ³n predice categorÃ­as. Por ejemplo: Â¿es un email spam o no? Â¿Un tumor es benigno o maligno? La regresiÃ³n logÃ­stica es un algoritmo que responde preguntas de "sÃ­ o no" (o mÃ¡s generalmente, preguntas con dos opciones).

La regresiÃ³n logÃ­stica usa la funciÃ³n sigmoide:

$$\sigma(x) = \frac{1}{1 + e^{-x}}$$

Esta funciÃ³n convierte cualquier nÃºmero en un valor entre 0 y 1, que podemos interpretar como una probabilidad.

### Visualizaciones Generadas

#### 2.1 ExploraciÃ³n de Datos con Histogramas
![Datos con histogramas](imgs/02_clasificacion_1_datos_histogramas.jpg)

Esta grÃ¡fica combina tres elementos:
- **Centro**: Scatter plot mostrando dos clases de datos (clase 0 en azul, clase 1 en rojo)
- **Arriba**: Histograma de la variable X por clase
- **Derecha**: Histograma de la variable Y por clase

Los histogramas nos ayudan a ver si las dos clases se pueden separar fÃ¡cilmente. Si los histogramas de cada color estÃ¡n muy mezclados, serÃ¡ difÃ­cil clasificar correctamente.

#### 2.2 Matriz de ConfusiÃ³n
![Matriz de confusiÃ³n](imgs/02_clasificacion_2_matriz_confusion.jpg)

La matriz de confusiÃ³n es como una tabla de calificaciones del modelo. Muestra:
- **Verdaderos Negativos (TN)**: Casos de clase 0 que predijimos correctamente como 0
- **Falsos Positivos (FP)**: Casos de clase 0 que incorrectamente predijimos como 1
- **Falsos Negativos (FN)**: Casos de clase 1 que incorrectamente predijimos como 0
- **Verdaderos Positivos (TP)**: Casos de clase 1 que predijimos correctamente como 1

Los nÃºmeros grandes en la diagonal (TN y TP) son buenos. Los nÃºmeros en las otras posiciones son errores.

#### 2.3 Curva ROC
![Curva ROC](imgs/02_clasificacion_3_curva_roc.jpg)

La curva ROC (Receiver Operating Characteristic) mide quÃ© tan bien el modelo distingue entre las dos clases. 

- El Ã¡rea bajo la curva (AUC) va de 0 a 1
- AUC = 0.5 significa que el modelo es tan bueno como lanzar una moneda (aleatorio)
- AUC = 1.0 significa que el modelo es perfecto
- La lÃ­nea diagonal punteada representa un clasificador aleatorio

Cuanto mÃ¡s se acerca la curva a la esquina superior izquierda, mejor es el modelo.

#### 2.4 Frontera de DecisiÃ³n
![Frontera de decisiÃ³n](imgs/02_clasificacion_4_frontera_decision.jpg)

Esta es una de las visualizaciones mÃ¡s importantes. Muestra:
- Los puntos de datos reales (azules y rojos)
- Las regiones de color de fondo muestran quÃ© clase predice el modelo en cada zona
- La lÃ­nea que separa las regiones es la "frontera de decisiÃ³n"

El modelo clasifica cualquier punto en la zona azul como clase 0, y cualquier punto en la zona roja como clase 1.

#### 2.5 DistribuciÃ³n de Probabilidades
![DistribuciÃ³n de probabilidades](imgs/02_clasificacion_5_distribucion_probabilidades.jpg)

Esta grÃ¡fica muestra las probabilidades que el modelo asigna a cada predicciÃ³n:
- Histograma azul: probabilidades asignadas a casos de clase 0
- Histograma rojo: probabilidades asignadas a casos de clase 1
- LÃ­nea negra vertical: umbral de decisiÃ³n (0.5)

Idealmente, las probabilidades de clase 0 deberÃ­an estar cerca de 0, y las de clase 1 cerca de 1. Si hay mucha superposiciÃ³n en el medio, significa que el modelo tiene incertidumbre.

### ConclusiÃ³n

La regresiÃ³n logÃ­stica es ideal cuando:
- Necesitamos clasificar datos en dos categorÃ­as
- Queremos conocer la probabilidad de cada predicciÃ³n
- Los datos son aproximadamente separables por una lÃ­nea o curva suave

---

## 3. ClasificaciÃ³n Multi-clase: Iris Dataset

**Script:** `03_clasificacion_ejemplo.py`

### Â¿QuÃ© es la ClasificaciÃ³n Multi-clase?

En el ejemplo anterior vimos clasificaciÃ³n binaria (2 clases). Pero Â¿quÃ© pasa si tenemos 3 o mÃ¡s categorÃ­as? Por ejemplo, clasificar tipos de flores (setosa, versicolor, virginica) o reconocer dÃ­gitos escritos (0-9).

En este ejemplo usamos el famoso dataset Iris que contiene mediciones de 3 especies de flores. Comparamos dos algoritmos:
- **RegresiÃ³n LogÃ­stica**: Extiende la regresiÃ³n logÃ­stica binaria a mÃºltiples clases
- **Random Forest**: Un conjunto de "Ã¡rboles de decisiÃ³n" que votan por la mejor respuesta

### Visualizaciones Generadas

#### 3.1 DistribuciÃ³n de Features por Clase
![Histogramas de features](imgs/03_clasificacion_iris_1_histogramas_features.jpg)

Estos 4 histogramas muestran cÃ³mo se distribuyen las 4 caracterÃ­sticas medidas (largo y ancho de sÃ©palo y pÃ©talo) para cada especie de flor:
- Verde: Setosa
- Naranja: Versicolor  
- Azul: Virginica

Si los histogramas de cada color estÃ¡n bien separados para una caracterÃ­stica, significa que esa caracterÃ­stica es muy Ãºtil para distinguir las especies.

#### 3.2 Relaciones entre CaracterÃ­sticas
![Scatter sÃ©palos y pÃ©talos](imgs/03_clasificacion_iris_2_scatter_sepalos_petalos.jpg)

Estos scatter plots muestran cÃ³mo se relacionan las caracterÃ­sticas entre sÃ­:
- **Izquierda**: RelaciÃ³n entre largo y ancho del sÃ©palo
- **Derecha**: RelaciÃ³n entre largo y ancho del pÃ©talo

Podemos ver que las flores setosa son muy diferentes (puntos verdes separados), mientras que versicolor y virginica se parecen mÃ¡s.

#### 3.3 Matriz de CorrelaciÃ³n
![Matriz de correlaciÃ³n](imgs/03_clasificacion_iris_3_matriz_correlacion.jpg)

Esta matriz muestra quÃ© tan relacionadas estÃ¡n las caracterÃ­sticas entre sÃ­:
- Valores cercanos a 1 (rojo): fuertemente correlacionadas (cuando una sube, la otra tambiÃ©n)
- Valores cercanos a -1 (azul): correlaciÃ³n negativa (cuando una sube, la otra baja)
- Valores cercanos a 0 (blanco): no hay relaciÃ³n clara

Por ejemplo, el largo y ancho del pÃ©talo estÃ¡n muy correlacionados (0.96), lo que significa que flores con pÃ©talos largos tambiÃ©n tienden a tener pÃ©talos anchos.

#### 3.4 ComparaciÃ³n de Modelos: Matrices y MÃ©tricas
![ComparaciÃ³n de modelos](imgs/03_clasificacion_iris_4_comparacion_matrices_metricas.jpg)

Esta visualizaciÃ³n compara los dos algoritmos:
- **Arriba izquierda**: Accuracy general de cada modelo
- **Arriba derecha**: Precision por cada especie

Podemos ver que Random Forest generalmente obtiene mejores resultados que RegresiÃ³n LogÃ­stica en este problema. La precision nos dice: de todas las veces que el modelo dijo "es una setosa", Â¿cuÃ¡ntas veces tuvo razÃ³n?

### ConclusiÃ³n

Para clasificaciÃ³n multi-clase:
- Algoritmos mÃ¡s complejos (Random Forest) suelen ser mÃ¡s precisos
- Es importante analizar el rendimiento en cada clase, no solo el promedio
- Visualizar los datos ayuda a entender quÃ© caracterÃ­sticas son mÃ¡s importantes

---

## 4. Clustering: Agrupamiento de Datos

**Script:** `04_clusterizacion.py`

### Â¿QuÃ© es el Clustering?

El clustering es diferente a la clasificaciÃ³n: no tenemos etiquetas previas. Es como si te dieran un montÃ³n de objetos mezclados y te pidieran agruparlos sin decirte los criterios. El algoritmo encuentra patrones por sÃ­ mismo y agrupa datos similares.

Probamos tres algoritmos:
- **K-Means**: Divide los datos en K grupos circulares
- **Agglomerative Clustering**: Va uniendo puntos cercanos paso a paso
- **DBSCAN**: Encuentra grupos de cualquier forma basÃ¡ndose en densidad

### Visualizaciones Generadas

#### 4.1 DistribuciÃ³n de CaracterÃ­sticas por Especie
![Histogramas de features](imgs/04_clusterizacion_1_histogramas_features.jpg)

Aunque estamos haciendo clustering (sin etiquetas), estos histogramas muestran las especies reales de pingÃ¼inos para que podamos evaluar despuÃ©s si el clustering las descubriÃ³ correctamente. Vemos 4 caracterÃ­sticas fÃ­sicas de los pingÃ¼inos: longitud del pico, profundidad del pico, largo de aleta y masa corporal.

#### 4.2 Relaciones entre CaracterÃ­sticas FÃ­sicas
![Scatter de caracterÃ­sticas](imgs/04_clusterizacion_2_scatter_caracteristicas.jpg)

Estos scatter plots muestran:
- **Izquierda**: Dimensiones del pico
- **Derecha**: TamaÃ±o fÃ­sico general

Los tres colores representan las tres especies reales. Podemos ver que los pingÃ¼inos Adelie (naranjas) son bastante diferentes de los otros dos, lo que sugiere que el clustering deberÃ­a poder identificarlos fÃ¡cilmente.

#### 4.3 Matriz de CorrelaciÃ³n
![Matriz de correlaciÃ³n](imgs/04_clusterizacion_3_matriz_correlacion.jpg)

Similar al ejemplo anterior, esta matriz muestra quÃ© caracterÃ­sticas estÃ¡n relacionadas. Por ejemplo, la masa corporal estÃ¡ fuertemente correlacionada con el largo de la aleta (0.87), lo que tiene sentido: pingÃ¼inos mÃ¡s grandes tienden a tener aletas mÃ¡s grandes.

#### 4.4 MÃ©todo del Codo
![MÃ©todo del codo](imgs/04_clusterizacion_4_metodo_codo.jpg)

Â¿CuÃ¡ntos grupos deberÃ­amos buscar? Estas dos grÃ¡ficas nos ayudan a decidir:

- **Izquierda (Inercia)**: Mide quÃ© tan compactos son los grupos. Queremos encontrar el "codo" donde la curva deja de mejorar dramÃ¡ticamente.
- **Derecha (Silhouette Score)**: Mide quÃ© tan bien separados estÃ¡n los grupos (valores cercanos a 1 son mejores).

En este caso, k=3 parece ser Ã³ptimo, Â¡que casualmente coincide con las 3 especies reales!

#### 4.5 VisualizaciÃ³n de Clusters en 2D (PCA)
![Clusters en PCA](imgs/04_clusterizacion_5_clusters_pca.jpg)

Para visualizar los datos en 2D, usamos PCA (AnÃ¡lisis de Componentes Principales), que es como tomar una foto de los datos desde el mejor Ã¡ngulo posible. Estas 4 grÃ¡ficas muestran:

- **Arriba izquierda**: Las especies reales
- **Arriba derecha**: Grupos encontrados por K-Means
- **Abajo izquierda**: Grupos encontrados por Clustering JerÃ¡rquico
- **Abajo derecha**: Grupos encontrados por DBSCAN

Comparando con las especies reales, podemos ver quÃ© algoritmo funcionÃ³ mejor. K-Means y JerÃ¡rquico lograron una separaciÃ³n muy similar a la real.

#### 4.6 ComparaciÃ³n de Algoritmos
![ComparaciÃ³n de algoritmos](imgs/04_clusterizacion_6_comparacion_algoritmos.jpg)

Esta grÃ¡fica compara directamente los algoritmos usando el Silhouette Score. Un valor mÃ¡s alto significa mejor separaciÃ³n entre grupos. Vemos que K-Means y Clustering JerÃ¡rquico obtuvieron resultados similares y buenos.

### ConclusiÃ³n

El clustering es Ãºtil cuando:
- No tenemos etiquetas en nuestros datos
- Queremos descubrir patrones ocultos o segmentos naturales
- Necesitamos agrupar clientes, documentos, imÃ¡genes, etc.

---

## 5. Competencia de Modelos de RegresiÃ³n

**Script:** `05_competencia_modelos_regresion.py`

### Â¿Por quÃ© comparar modelos?

No existe un modelo perfecto para todos los problemas. Cada algoritmo tiene fortalezas y debilidades. En este script probamos 11 modelos diferentes de regresiÃ³n para predecir precios de viviendas en California y vemos cuÃ¡l funciona mejor.

Los modelos comparados incluyen:
- Modelos lineales: Linear Regression, Ridge, Lasso, ElasticNet
- Modelos basados en Ã¡rboles: Decision Tree, Random Forest, Gradient Boosting, AdaBoost, XGBoost
- Otros: KNN, SVR

### MÃ©tricas de EvaluaciÃ³n

Usamos dos mÃ©tricas principales:
- **RÂ² (R-cuadrado)**: Va de 0 a 1. Valores cercanos a 1 significan que el modelo explica muy bien los datos.
- **RMSE (Error CuadrÃ¡tico Medio)**: El error promedio de las predicciones. Valores mÃ¡s bajos son mejores.

### Visualizaciones Generadas

#### 5.1 DistribuciÃ³n de la Variable Objetivo
![DistribuciÃ³n del target](imgs/05_regresion_comp_1_distribucion_target.jpg)

Estas grÃ¡ficas muestran la distribuciÃ³n de los precios de las viviendas:
- **Izquierda (Histograma)**: La mayorÃ­a de las casas cuestan entre $1-3 (en unidades de $100,000)
- **Derecha (Box Plot)**: Muestra la mediana, cuartiles y valores atÃ­picos

Podemos ver que hay algunas casas muy caras (outliers), pero la mayorÃ­a estÃ¡n en un rango mÃ¡s moderado.

#### 5.2 DistribuciÃ³n de CaracterÃ­sticas
![Histogramas de features](imgs/05_regresion_comp_2_histogramas_features.jpg)

Cuatro caracterÃ­sticas importantes:
- **MedInc**: Ingreso medio de la zona
- **HouseAge**: Edad promedio de las casas
- **AveRooms**: NÃºmero promedio de habitaciones
- **Population**: PoblaciÃ³n de la zona

Cada una tiene una distribuciÃ³n diferente que el modelo debe aprender a usar para predecir precios.

#### 5.3 RelaciÃ³n entre CaracterÃ­sticas y Precio
![Scatter features vs target](imgs/05_regresion_comp_3_scatter_features_vs_target.jpg)

Estos scatter plots muestran cÃ³mo cada caracterÃ­stica se relaciona con el precio:
- **MedInc** muestra una relaciÃ³n clara: mayor ingreso â†’ mayor precio
- Las otras caracterÃ­sticas muestran patrones mÃ¡s complejos

Estas visualizaciones nos ayudan a entender quÃ© caracterÃ­sticas son mÃ¡s predictivas.

#### 5.4 Matriz de CorrelaciÃ³n
![Matriz de correlaciÃ³n](imgs/05_regresion_comp_4_matriz_correlacion.jpg)

Esta matriz muestra todas las relaciones entre variables. Lo mÃ¡s importante es la Ãºltima columna/fila (MedHouseVal), que muestra quÃ© caracterÃ­sticas estÃ¡n mÃ¡s correlacionadas con el precio. MedInc (ingreso medio) tiene la correlaciÃ³n mÃ¡s fuerte (0.69).

#### 5.5 Mapa GeogrÃ¡fico de Precios
![Mapa geogrÃ¡fico](imgs/05_regresion_comp_5_mapa_geografico.jpg)

Esta es una visualizaciÃ³n especial: cada punto es una ubicaciÃ³n en California, y el color representa el precio. Podemos ver claramente que:
- Las zonas costeras (especialmente cerca de San Francisco y Los Ãngeles) son mÃ¡s caras (colores cÃ¡lidos)
- Las zonas del interior son mÃ¡s baratas (colores frÃ­os)

Â¡La ubicaciÃ³n geogrÃ¡fica es muy importante para el precio!

#### 5.6 ComparaciÃ³n de MÃ©tricas entre Modelos
![ComparaciÃ³n de mÃ©tricas](imgs/05_regresion_comp_6_comparacion_metricas.jpg)

Dos grÃ¡ficas de barras que comparan todos los modelos:
- **Arriba**: RÂ² Score (mayor es mejor) - el modelo ganador estÃ¡ en dorado
- **Abajo**: RMSE (menor es mejor) - el modelo ganador estÃ¡ en dorado

Podemos ver rÃ¡pidamente quÃ© modelos funcionaron mejor. Los modelos de ensemble (Gradient Boosting, Random Forest) suelen estar en el top.

#### 5.7 DispersiÃ³n RÂ² vs RMSE
![Scatter RÂ² vs RMSE](imgs/05_regresion_comp_7_scatter_r2_vs_rmse.jpg)

Esta grÃ¡fica muestra ambas mÃ©tricas simultÃ¡neamente. Cada punto es un modelo. El modelo ideal estarÃ­a en la esquina superior derecha (alto RÂ², bajo RMSE). Los modelos marcados en rojo estÃ¡n en la "zona excelente" (RÂ² > 0.8).

#### 5.8 AnÃ¡lisis de Residuos del Mejor Modelo
![AnÃ¡lisis de residuos](imgs/05_regresion_comp_8_analisis_residuos.jpg)

Un anÃ¡lisis profundo del mejor modelo a travÃ©s de 4 grÃ¡ficas:

1. **Predicciones vs Valores Reales**: Los puntos deberÃ­an estar cerca de la lÃ­nea roja diagonal. Cuanto mÃ¡s dispersos, peor es el modelo.

2. **DistribuciÃ³n de Residuos**: Los residuos (errores) deberÃ­an formar una campana centrada en 0. Esto significa que el modelo no tiene sesgo sistemÃ¡tico.

3. **Residuos vs Predicciones**: No deberÃ­a haber patrones claros. Si hay un patrÃ³n (como un embudo), significa que el modelo funciona mejor en ciertos rangos de precio.

4. **Q-Q Plot**: Los puntos deberÃ­an estar sobre la lÃ­nea diagonal. Esto verifica si los residuos siguen una distribuciÃ³n normal.

#### 5.9 Importancia de CaracterÃ­sticas
![Feature importance](imgs/05_regresion_comp_9_feature_importance.jpg)

Esta grÃ¡fica muestra quÃ© caracterÃ­sticas son mÃ¡s importantes para el mejor modelo. Por ejemplo, si el mejor modelo es Random Forest o Gradient Boosting, podemos ver que MedInc (ingreso medio) es tÃ­picamente la caracterÃ­stica mÃ¡s importante, seguida de ubicaciÃ³n (Latitude, Longitude).

### ConclusiÃ³n

Este anÃ¡lisis nos enseÃ±a que:
- Diferentes modelos tienen diferentes fortalezas
- Los modelos de ensemble (que combinan mÃºltiples modelos) suelen funcionar mejor
- Es importante no solo mirar la precisiÃ³n, sino tambiÃ©n analizar los errores
- La importancia de caracterÃ­sticas nos ayuda a entender quÃ© factores impulsan las predicciones

---

## 6. Competencia de Modelos de ClasificaciÃ³n

**Script:** `06_competencia_modelos_clasificacion.py`

### Competencia para ClasificaciÃ³n Binaria

Similar al script anterior, pero para clasificaciÃ³n. Usamos el dataset de CÃ¡ncer de Mama de Wisconsin para predecir si un tumor es benigno o maligno. Probamos 8 modelos diferentes:

- RegresiÃ³n LogÃ­stica
- K-Nearest Neighbors (KNN)
- Decision Tree
- Random Forest
- Support Vector Machine (SVM)
- Gaussian Naive Bayes
- Gradient Boosting
- AdaBoost

### MÃ©tricas de EvaluaciÃ³n

Para clasificaciÃ³n usamos:
- **Accuracy**: % de predicciones correctas
- **Precision**: De los casos que predijimos como positivos, Â¿cuÃ¡ntos realmente lo eran?
- **Recall**: De todos los casos positivos reales, Â¿cuÃ¡ntos detectamos?
- **F1-Score**: Promedio armÃ³nico de Precision y Recall
- **ROC-AUC**: Ãrea bajo la curva ROC

### Visualizaciones Generadas

#### 6.1 ExploraciÃ³n de Datos
![ExploraciÃ³n de datos](imgs/06_clasificacion_comp_1_exploracion_datos.jpg)

Cuatro visualizaciones exploratorias:
1. **Arriba izquierda (Pie Chart)**: ProporciÃ³n de tumores benignos vs malignos en el dataset
2. **Arriba derecha (Violin Plot)**: DistribuciÃ³n de la feature mÃ¡s importante por clase. El "violÃ­n" muestra la densidad de los datos.
3. **Abajo izquierda (Heatmap)**: CorrelaciÃ³n entre las primeras caracterÃ­sticas
4. **Abajo derecha (Scatter)**: RelaciÃ³n entre dos caracterÃ­sticas importantes, coloreadas por clase

#### 6.2 ComparaciÃ³n de MÃ©tricas entre Modelos
![ComparaciÃ³n de mÃ©tricas](imgs/06_clasificacion_comp_2_comparacion_metricas.jpg)

Cuatro visualizaciones que comparan los modelos:
1. **Arriba izquierda**: Accuracy de cada modelo
2. **Arriba derecha**: F1-Score de cada modelo
3. **Abajo izquierda**: Precision vs Recall (cada punto es un modelo)
4. **Abajo derecha**: GrÃ¡fica de radar comparando los top 3 modelos en mÃºltiples mÃ©tricas simultÃ¡neamente

La grÃ¡fica de radar es especialmente Ãºtil porque muestra el perfil completo de cada modelo de un vistazo.

#### 6.3 AnÃ¡lisis Detallado del Mejor Modelo
![Mejor modelo: confusiÃ³n y ROC](imgs/06_clasificacion_comp_3_mejor_modelo_confusion_roc.jpg)

Dos visualizaciones del modelo ganador:
- **Izquierda**: Matriz de confusiÃ³n con porcentajes. Muestra exactamente cuÃ¡ntos casos clasificÃ³ bien y mal.
- **Derecha**: Curva ROC especÃ­fica de este modelo

Esta visualizaciÃ³n nos da confianza en el modelo ganador al ver su desempeÃ±o detallado.

#### 6.4 Curvas ROC de Todos los Modelos
![Curvas ROC de todos](imgs/06_clasificacion_comp_4_curvas_roc_todos.jpg)

Todas las curvas ROC superpuestas en una sola grÃ¡fica. Esto permite comparar visualmente todos los modelos. Las curvas que estÃ¡n mÃ¡s cerca de la esquina superior izquierda son mejores. Podemos ver que la mayorÃ­a de los modelos funcionan muy bien (AUC > 0.95), lo que significa que este problema es relativamente "fÃ¡cil" para machine learning.

#### 6.5 Importancia de CaracterÃ­sticas
![Feature importance](imgs/06_clasificacion_comp_5_feature_importance.jpg)

Muestra las 15 caracterÃ­sticas mÃ¡s importantes para el mejor modelo. Esto nos dice quÃ© mediciones del tumor son mÃ¡s Ãºtiles para distinguir entre benigno y maligno. Por ejemplo, caracterÃ­sticas como "worst perimeter" (perÃ­metro peor) y "worst area" (Ã¡rea peor) suelen ser muy predictivas.

### ConclusiÃ³n

Este anÃ¡lisis demuestra que:
- Para problemas mÃ©dicos crÃ­ticos, queremos modelos con muy alta precision (evitar falsos positivos) y recall (no perder casos positivos)
- MÃºltiples modelos pueden lograr excelente desempeÃ±o en el mismo problema
- La curva ROC nos ayuda a seleccionar el umbral Ã³ptimo segÃºn nuestras prioridades (Â¿es peor un falso positivo o un falso negativo?)
- La importancia de caracterÃ­sticas puede validarse con conocimiento mÃ©dico experto

---

## ğŸ¯ Resumen General

Este repositorio te lleva en un viaje desde los conceptos mÃ¡s bÃ¡sicos (regresiÃ³n lineal simple) hasta tÃ©cnicas avanzadas (competencias de modelos con validaciÃ³n cruzada). Cada ejemplo incluye:

âœ… CÃ³digo bien documentado
âœ… Visualizaciones claras y didÃ¡cticas  
âœ… Explicaciones en lenguaje simple
âœ… MÃ©tricas de evaluaciÃ³n apropiadas
âœ… Comparaciones entre diferentes enfoques

## ğŸ“¦ Requisitos

Para ejecutar los scripts necesitas instalar:
```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost scipy
```

## ğŸš€ CÃ³mo Usar

1. Ejecuta cada script de Python en orden (01, 02, 03...)
2. Las grÃ¡ficas se guardarÃ¡n automÃ¡ticamente en `imgs/`
3. TambiÃ©n se mostrarÃ¡n en pantalla durante la ejecuciÃ³n
4. Lee este README junto con las visualizaciones para entender cada concepto

## ğŸ“š Recursos para Aprender MÃ¡s

- DocumentaciÃ³n de scikit-learn: https://scikit-learn.org/
- Curso de Machine Learning de Andrew Ng (Coursera)
- "Introduction to Statistical Learning" (libro gratuito en PDF)

---

**Â¡Feliz aprendizaje! ğŸ“**

